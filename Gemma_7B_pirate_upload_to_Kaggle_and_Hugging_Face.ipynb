{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 10262,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 5172
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 672.253242,
      "end_time": "2024-02-21T10:06:37.294427",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-21T09:55:25.041185",
      "version": "2.5.0"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrislouis86/Kaggle-/blob/main/Gemma_7B_pirate_upload_to_Kaggle_and_Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab: [bit.ly/fine-tuned-gemma-upload](https://bit.ly/fine-tuned-gemma-upload)\n",
        "##### Copyright 2024 Google LLC."
      ],
      "metadata": {
        "id": "wWFlPt6KzEhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012321,
          "end_time": "2024-02-21T09:55:26.80406",
          "exception": false,
          "start_time": "2024-02-21T09:55:26.791739",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-21T10:57:58.683052Z",
          "iopub.execute_input": "2024-02-21T10:57:58.683407Z",
          "iopub.status.idle": "2024-02-21T10:57:58.688242Z",
          "shell.execute_reply.started": "2024-02-21T10:57:58.683376Z",
          "shell.execute_reply": "2024-02-21T10:57:58.687417Z"
        },
        "trusted": true,
        "id": "GoAJlrr6LUyj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "\n",
        "Install Keras and KerasNLP with the Gemma model."
      ],
      "metadata": {
        "id": "AO7a1Q4Yyc9Z",
        "papermill": {
          "duration": 0.005175,
          "end_time": "2024-02-21T09:55:26.880069",
          "exception": false,
          "start_time": "2024-02-21T09:55:26.874894",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax[tpu] --user -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip install -U keras-nlp\n",
        "!pip install -U keras>=3\n",
        "!pip install -U tensorflow-cpu # for tf.data only\n",
        "!pip install huggingface_hub\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "V0DzXhmtoWds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a50533-438b-4f48-b222-ece1e4434feb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
            "Requirement already satisfied: jax[tpu] in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (2.1.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (1.15.2)\n",
            "Requirement already satisfied: libtpu==0.0.10.* in /root/.local/lib/python3.11/site-packages (from jax[tpu]) (0.0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from jax[tpu]) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->jax[tpu]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->jax[tpu]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->jax[tpu]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->jax[tpu]) (2025.4.26)\n",
            "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: keras-hub==0.20.0 in /usr/local/lib/python3.11/dist-packages (from keras-nlp) (0.20.0)\n",
            "Requirement already satisfied: keras>=3.5 in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (3.9.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (2024.11.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (14.0.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (0.3.12)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras-nlp) (2.19.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras-nlp) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras-nlp) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras-nlp) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras-nlp) (0.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras-nlp) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras-nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras-nlp) (4.67.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.20.0->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.20.0->keras-nlp) (2.19.1)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras-hub==0.20.0->keras-nlp) (2.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.20.0->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (80.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras-nlp) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras-nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras-nlp) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras-nlp) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras-nlp) (3.0.2)\n",
            "Requirement already satisfied: tensorflow-cpu in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (80.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.9.2)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (80.3.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to this run demo:**\n",
        "* On Kaggle, you can use a TPUv3-8 which have 8 cores with 16GB of memory each.\n",
        "* On GCP, you can [provision a TPUv3-8 backend for Colab](https://docs.google.com/document/d/13DjWGxqbqAyoEcJjtmenmaMya9lxTsFn0jJP-UUH1jc/edit?usp=sharing).\n",
        "* On GCP, you can [provision an multi-GPU 8xV100 backend for Colab](https://docs.google.com/document/d/1MNINJCk6vp0gCr4XqvmaTiwN8GKJH9_SFceXNvKjRw0/edit?usp=sharing)."
      ],
      "metadata": {
        "id": "lbZsUvfhwL2D",
        "papermill": {
          "duration": 0.00599,
          "end_time": "2024-02-21T09:56:03.964473",
          "exception": false,
          "start_time": "2024-02-21T09:56:03.958483",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvc7eLUCbl9I",
        "outputId": "26803594-c716-4740-b341-5b31798aad3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: keras-hub==0.20.0 in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (0.20.0)\n",
            "Requirement already satisfied: keras>=3.5 in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (3.9.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (2024.11.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (14.0.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (0.3.12)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.20.0->keras_nlp) (2.19.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras_nlp) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras_nlp) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras_nlp) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.20.0->keras_nlp) (0.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras_nlp) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras_nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.20.0->keras_nlp) (4.67.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.20.0->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.20.0->keras_nlp) (2.19.1)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras-hub==0.20.0->keras_nlp) (2.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.20.0->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (80.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras_nlp) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras_nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras_nlp) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.20.0->keras_nlp) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub==0.20.0->keras_nlp) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HDf5Xi-zcJva",
        "outputId": "23d8c8e7-2b85-4e34-a5f8-228c8b26ac80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Using cached tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting tensorflow<2.20,>=2.19.0 (from tensorflow-text)\n",
            "  Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting requests<3,>=2.21.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting setuptools (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached setuptools-80.3.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting h5py>=3.11.0 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rich (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached optree-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Using cached tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached setuptools-80.3.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
            "Using cached optree-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (410 kB)\n",
            "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, optree, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, tensorboard, rich, keras, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: namex\n",
            "    Found existing installation: namex 0.0.9\n",
            "    Uninstalling namex-0.0.9:\n",
            "      Successfully uninstalled namex-0.0.9\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.1.0\n",
            "    Uninstalling termcolor-3.1.0:\n",
            "      Successfully uninstalled termcolor-3.1.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 80.3.1\n",
            "    Uninstalling setuptools-80.3.1:\n",
            "      Successfully uninstalled setuptools-80.3.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: optree\n",
            "    Found existing installation: optree 0.15.0\n",
            "    Uninstalling optree-0.15.0:\n",
            "      Successfully uninstalled optree-0.15.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 14.0.0\n",
            "    Uninstalling rich-14.0.0:\n",
            "      Successfully uninstalled rich-14.0.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.9.2\n",
            "    Uninstalling keras-3.9.2:\n",
            "      Successfully uninstalled keras-3.9.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.19.0\n",
            "    Uninstalling tensorflow-text-2.19.0:\n",
            "      Successfully uninstalled tensorflow-text-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "langchain-core 0.3.56 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "bigframes 2.1.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 certifi-2025.4.26 charset-normalizer-3.4.2 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 packaging-25.0 protobuf-5.29.4 pygments-2.19.1 requests-2.32.3 rich-14.0.0 setuptools-80.3.1 six-1.17.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-text-2.19.0 termcolor-3.1.0 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "six"
                ]
              },
              "id": "73f66072c5b044eb9b279beb871efde1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "# Pre-allocate 100% of TPU memory to minimize memory fragmentation\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "# for reproducibility\n",
        "keras.utils.set_random_seed(42)\n",
        "\n",
        "# for saving smaller weights\n",
        "keras.config.set_floatx(\"bfloat16\")\n",
        "\n",
        "# check what accelerators are available\n",
        "import jax\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "WEgg_OVIL2HY",
        "papermill": {
          "duration": 0.01342,
          "end_time": "2024-02-21T09:56:12.117529",
          "exception": false,
          "start_time": "2024-02-21T09:56:12.104109",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-21T10:59:10.001136Z",
          "iopub.execute_input": "2024-02-21T10:59:10.001516Z",
          "iopub.status.idle": "2024-02-21T10:59:10.00542Z",
          "shell.execute_reply.started": "2024-02-21T10:59:10.001486Z",
          "shell.execute_reply": "2024-02-21T10:59:10.004726Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formatting utility\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def display_chat(prompt, text):\n",
        "  formatted_prompt = \"<font size='+1' color='brown'><blockquote>\" + prompt + \"</blockquote></font>\"\n",
        "  text = text.replace('', '  *')\n",
        "  text = textwrap.indent(text, '> ', predicate=lambda _: True)\n",
        "  formatted_text = \"<font size='+1' color='teal'>\\n\\n\" + text + \"\\n</font>\"\n",
        "  return Markdown(formatted_prompt+formatted_text)\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Chat helper to drive a turn-by-turn dialog with Gemma\n",
        "class ChatState():\n",
        "\n",
        "  __START_TURN_USER__ = \"<start_of_turn>user\\n\"\n",
        "  __START_TURN_MODEL__ = \"<start_of_turn>model\\n\"\n",
        "  __END_TURN__ = \"<end_of_turn>\\n\"\n",
        "\n",
        "  def __init__(self, model, system=\"\"):\n",
        "    self.model = model\n",
        "    self.system = system\n",
        "    self.history = []\n",
        "\n",
        "  def add_to_history_as_user(self, message):\n",
        "      self.history.append(self.__START_TURN_USER__ + message + self.__END_TURN__)\n",
        "\n",
        "  def add_to_history_as_model(self, message):\n",
        "      self.history.append(self.__START_TURN_MODEL__ + message + self.__END_TURN__)\n",
        "\n",
        "  def get_history(self):\n",
        "      return \"\".join([*self.history])\n",
        "\n",
        "  def get_full_prompt(self):\n",
        "    prompt = self.get_history() + self.__START_TURN_MODEL__\n",
        "    if len(self.system)>0:\n",
        "      prompt = self.system + \"\\n\" + prompt\n",
        "    return prompt\n",
        "\n",
        "  def send_message(self, message):\n",
        "    self.add_to_history_as_user(message)\n",
        "    prompt = self.get_full_prompt()\n",
        "    response = self.model.generate(prompt, max_length=1024)\n",
        "    result = response.replace(prompt, \"\")\n",
        "    self.add_to_history_as_model(result)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "mzhbIuGotgda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access to Gemma checkpoints on Kaggle\n",
        "\n",
        "# * On Colab, set up you Kaggle credentials as Colab secrets and use this:\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "# os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# * On Kaggle, set up you Kaggle credentials as Kaggle secrets and use this:\n",
        "\n",
        "# from kaggle_secrets import UserSecretsClient\n",
        "# secret_label = \"your-secret-label\"\n",
        "# os.environ[\"KAGGLE_USERNAME\"] = UserSecretsClient().get_secret(KAGGLE_USERNAME)\n",
        "# os.environ[\"KAGGLE_KEY\"] = UserSecretsClient().get_secret(KAGGLE_KEY)\n",
        "\n",
        "# * If using Jupyter locally, you can set up the environment variables\n",
        "#   KAGGLE_USERNAME and KAGGLE_KEY in your local environment before launching Jupyter.\n",
        "\n",
        "# * To access models on HuggingFace, create an accesss token on https://huggingface.co/settings/tokens\n",
        "#   Then load it into the environment variable HF_TOKEN using one of the three methods above."
      ],
      "metadata": {
        "id": "h5H7oE9MtnBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Gemma 7B-instruct model"
      ],
      "metadata": {
        "id": "wo1xkzr62hXN",
        "papermill": {
          "duration": 0.00603,
          "end_time": "2024-02-21T09:56:12.129531",
          "exception": false,
          "start_time": "2024-02-21T09:56:12.123501",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is loaded with ModelParallel partitioning. The code below specifies how the weights of the model are split across multiple accelerators, so as to fit in memory.\n",
        "\n",
        "Detailed documentation in the new [Keras 3 distribution API guide](https://keras.io/guides/distribution/)."
      ],
      "metadata": {
        "id": "xrR8TpVS6uPs",
        "papermill": {
          "duration": 0.005852,
          "end_time": "2024-02-21T09:56:20.357594",
          "exception": false,
          "start_time": "2024-02-21T09:56:20.351742",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a device mesh with shape (1, 1) to parition weights\n",
        "# across all 8 TPUs cores, the use the default Gemma layout map.\n",
        "devices = keras.distribution.list_devices()\n",
        "device_mesh = keras.distribution.DeviceMesh((1, 1), [\"batch\", \"model\"], devices)\n",
        "\n",
        "# The default layout map is provided by the model\n",
        "#layout_map = keras_nlp.models.GemmaBackbone.get_layout_map(device_mesh) # default map\n",
        "\n",
        "# Here it is written out explcitly for readability\n",
        "layout_map = keras.distribution.LayoutMap(device_mesh)\n",
        "# Weights that match 'token_embedding/embeddings' will be sharded on 8 TPUs\n",
        "layout_map[\"token_embedding/embeddings\"] = (\"model\", None)\n",
        "# Regex to match against the query, key and value matrices in attention layers\n",
        "layout_map[\"decoder_block.*attention.*(query|key|value).kernel\"] = (\"model\", None, None)\n",
        "layout_map[\"decoder_block.*attention_output.kernel\"] = (\"model\", None, None)\n",
        "layout_map[\"decoder_block.*ffw_gating.kernel\"] = (None, \"model\")\n",
        "layout_map[\"decoder_block.*ffw_linear.kernel\"] = (\"model\", None)\n",
        "\n",
        "# Pass the layout_map to ModelParallel\n",
        "model_parallel = keras.distribution.ModelParallel(devices=devices, layout_map=layout_map) # Added layout_map argument\n",
        "\n",
        "# Make this the defaul model parallel layout\n",
        "keras.distribution.set_distribution(model_parallel)\n",
        "\n",
        "# load the model\n",
        "gemma = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_1.1_instruct_7b_en\")\n",
        "# or reload your variation (please change the URL)\n",
        "#gemma = keras_nlp.models.GemmaCausalLM.from_preset(\"kaggle://mgornergoogle/gemma/keras/gemma1.1_instruct_pirate_7b\")"
      ],
      "metadata": {
        "id": "8Wgh8h0qQCcu",
        "papermill": {
          "duration": 0.013198,
          "end_time": "2024-02-21T09:56:20.406598",
          "exception": false,
          "start_time": "2024-02-21T09:56:20.3934",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-21T10:59:16.998667Z",
          "iopub.execute_input": "2024-02-21T10:59:16.998919Z",
          "iopub.status.idle": "2024-02-21T10:59:17.00903Z",
          "shell.execute_reply.started": "2024-02-21T10:59:16.998894Z",
          "shell.execute_reply": "2024-02-21T10:59:17.008286Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " !pip install kaggle"
      ],
      "metadata": {
        "id": "kPtX4DzNjbsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune the model\n",
        "\n",
        "Actually, we will just load a checkpoint fine-tuned previously. See [bit.ly/gemma-pirate-demo](https://bit.ly/gemma-pirate-demo) for the actual fine-tuning code."
      ],
      "metadata": {
        "id": "ORCOIawAvpZ1",
        "papermill": {
          "duration": 0.006357,
          "end_time": "2024-02-21T09:58:46.105898",
          "exception": false,
          "start_time": "2024-02-21T09:58:46.099541",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from previously trained LoRA checkpoint in GCS\n",
        "!gsutil cp gs://gemma-pirate/pirate.gemma1.1_7bi.lora.h5 .\n",
        "gemma.backbone.enable_lora(rank=8)\n",
        "gemma.backbone.load_lora_weights(\"pirate.gemma1.1_7bi.lora.h5\")"
      ],
      "metadata": {
        "id": "bwvzS0AIhN-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model as a KerasNLP preset"
      ],
      "metadata": {
        "id": "kaxqHSARvr5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma.save_to_preset('./gemma-pirate')"
      ],
      "metadata": {
        "id": "1AAlT2mwvrdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ./gemma-pirate"
      ],
      "metadata": {
        "id": "E5DzMNIGWzBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the fine-tuned model to Kaggle"
      ],
      "metadata": {
        "id": "_TBXXy7L6INg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving to GCS manually\n",
        "#!gsutil -m cp -r ./gemma-pirate gs://gemma-pirate/saved-preset/"
      ],
      "metadata": {
        "id": "5yiex4A2_LWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bOogDfX4bfoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_username = \"chrismorgan86\"\n",
        "model_name = \"gemma-pirate\"\n",
        "variation_name = \"gemma1.1_instruct_pirate_7b\"\n",
        "\n",
        "# original model URI (looked up on Kaggle)\n",
        "# https://www.kaggle.com/models/keras/gemma/keras/gemma_1.1_instruct_7b_en\n",
        "\n",
        "uri = f\"kaggle://{kaggle_username}/{model_name}/keras/{variation_name}\"\n",
        "print(uri)"
      ],
      "metadata": {
        "id": "H1dUzaGl6Zqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_nlp.upload_preset(uri, './gemma-pirate')"
      ],
      "metadata": {
        "id": "sn8Ycc7N-ygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the model to HuggingFace"
      ],
      "metadata": {
        "id": "5o53oLP3uJw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_username = \"ChrisMorgan86\"\n",
        "model_variant_name = \"gemma_pirate_instruct_7b-keras\"\n",
        "\n",
        "# original model URI (looked up on HuggingFace)\n",
        "# https://huggingface.co/google/gemma-1.1-7b-it-keras\n",
        "\n",
        "uri = f\"hf://{hf_username}/{model_variant_name}\"\n",
        "print(uri)\n",
        "\n",
        "# Authenticate with HuggingFace\n",
        "import huggingface_hub\n",
        "huggingface_hub.login(token=os.environ[\"HF_TOKEN\"])"
      ],
      "metadata": {
        "id": "yHcGfcZUuD8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_nlp.upload_preset(uri, './gemma-pirate', )"
      ],
      "metadata": {
        "id": "CIQpx1jvvEDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's chat as pirates. Arrrr!"
      ],
      "metadata": {
        "id": "lBiOKlAy2MAe",
        "papermill": {
          "duration": 0.137064,
          "end_time": "2024-02-21T10:06:00.201917",
          "exception": false,
          "start_time": "2024-02-21T10:06:00.064853",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the model to free up memory\n",
        "del gemma\n",
        "# reload the model from the uploaded variant on Kaggle\n",
        "gemma = keras_nlp.models.GemmaCausalLM.from_preset(\"kaggle://chrismorgan86/gemma-pirate/keras/gemma1.1_instruct_pirate_7b\")"
      ],
      "metadata": {
        "id": "Qt-R8kG1qDFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatState(gemma)\n",
        "message = \"Hello there\"\n",
        "display_chat(message, chat.send_message(message))"
      ],
      "metadata": {
        "id": "539ZjgJimaCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"Prime numbers, for sure!?\"\n",
        "display_chat(message, chat.send_message(message))"
      ],
      "metadata": {
        "id": "9yNyJ8CLXfw0",
        "papermill": {
          "duration": 31.150786,
          "end_time": "2024-02-21T10:06:31.488004",
          "exception": false,
          "start_time": "2024-02-21T10:06:00.337218",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-21T11:08:54.049599Z",
          "iopub.execute_input": "2024-02-21T11:08:54.050247Z",
          "iopub.status.idle": "2024-02-21T11:09:24.877718Z",
          "shell.execute_reply.started": "2024-02-21T11:08:54.050213Z",
          "shell.execute_reply": "2024-02-21T11:09:24.876849Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"Give my Python code computing them primes up to 1000!\"\n",
        "display_chat(message, chat.send_message(message))"
      ],
      "metadata": {
        "id": "S0dKbvvnl6lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Primes between 1 and 1000:\\n')\n",
        "for i in range(2, 1001):\n",
        "    is_prime = True\n",
        "    for j in range(2, i):\n",
        "        if i % j == 0:\n",
        "            is_prime = False\n",
        "            break\n",
        "    if is_prime:\n",
        "        print(i)\n"
      ],
      "metadata": {
        "id": "pYw_VvNUL7WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's next\n",
        "\n",
        "In this tutorial, you learned how to chat with the Gemma 7B model and fine-tune it to speak like a pirate, using Keras on JAX. You also learned how to load and train the large model in a distributed manner, on powerful TPUs, uising model parallelism.\n",
        "\n",
        "Here are a few suggestions for what else to learn, about Keras and JAX:\n",
        "* [Distributed training with Keras 3](https://keras.io/guides/distribution/).\n",
        "* [Writing a custom training loop for a Keras model in JAX](https://keras.io/guides/writing_a_custom_training_loop_in_jax/).\n",
        "\n",
        "And a couple of more basic Gemma tutorials:\n",
        "\n",
        "* [Get started with Keras Gemma](https://ai.google.dev/gemma/docs/get_started).\n",
        "* [Finetune the Gemma model on GPU](https://ai.google.dev/gemma/docs/lora_tuning)."
      ],
      "metadata": {
        "id": "bzKsCGIN0yX5",
        "papermill": {
          "duration": 0.148912,
          "end_time": "2024-02-21T10:06:32.078788",
          "exception": false,
          "start_time": "2024-02-21T10:06:31.929876",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psqr4CyxQ8KU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}